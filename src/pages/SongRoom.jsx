import { useState, useEffect, useRef } from "react";
import { Room, LocalAudioTrack } from "livekit-client";

export default function SongRoom({ room, name, socket, currentSinger }) {
  const [lkRoom, setLkRoom] = useState(null);
  const [singing, setSinging] = useState(false);
  const [sharing, setSharing] = useState(false); // æ˜¯å¦å·²åˆ†äº«åˆ†é éŸ³

  const roomRef = useRef(null);
  const audioCtxRef = useRef(null);
  const destRef = useRef(null);

  useEffect(() => {
    if (!socket) return;

    socket.on("forceStopSing", () => {
      stopSing();
    });

    return () => {
      socket.off("forceStopSing");
    };
  }, [socket]);

  const startSing = async (jwtToken) => {
    try {
      const lk = new Room();
      roomRef.current = lk;
      await lk.connect(import.meta.env.VITE_LIVEKIT_URL, jwtToken);

      // å»ºç«‹ audio context
      const audioCtx = new AudioContext();
      audioCtxRef.current = audioCtx;
      const dest = audioCtx.createMediaStreamDestination();
      destRef.current = dest;

      // å…ˆæŠ“éº¥å…‹é¢¨
      const micStream = await navigator.mediaDevices.getUserMedia({
        audio: { echoCancellation: false, noiseSuppression: false, autoGainControl: false },
      });
      audioCtx.createMediaStreamSource(micStream).connect(dest);

      // ç™¼å¸ƒ track
      const track = new LocalAudioTrack(dest.stream.getAudioTracks()[0]);
      await lk.localParticipant.publishTrack(track);

      setLkRoom(lk);
      setSinging(true);
      console.log("[SongRoom] å·²ä¸Šéº¥ ğŸ¤");
    } catch (err) {
      console.error("[SongRoom] startSing failed:", err);
    }
  };

  const stopSing = () => {
    lkRoom?.localParticipant.unpublishTracks();
    lkRoom?.disconnect();
    audioCtxRef.current?.close();

    setLkRoom(null);
    setSinging(false);
    setSharing(false);
    socket.emit("stopSing", { room, singer: name });
    console.log("[SongRoom] å·²ä¸‹éº¥ ğŸ›‘");
  };

  const grabMic = () => {
    socket.emit("grabMic", { room, singer: name });
    socket.once("livekit-token", ({ token }) => {
      startSing(token);
    });
  };

  const shareTabAudio = async () => {
    if (!lkRoom || !destRef.current) return;
    try {
      const displayStream = await navigator.mediaDevices.getDisplayMedia({
        video: true,
        audio: { echoCancellation: false, noiseSuppression: false, autoGainControl: false },
      });
      const tabAudioTrack = displayStream.getAudioTracks()[0];
      if (tabAudioTrack) {
        const audioCtx = audioCtxRef.current;
        audioCtx.createMediaStreamSource(new MediaStream([tabAudioTrack])).connect(destRef.current);
        setSharing(true);
        console.log("[SongRoom] åˆ†é éŸ³å·²åŠ å…¥ ğŸ¶");
      }
    } catch (err) {
      console.error("[SongRoom] shareTabAudio failed:", err);
    }
  };

  const otherSinger = currentSinger && currentSinger !== name;
  const grabDisabled = !singing && otherSinger;
  const grabTitle = grabDisabled ? "è«‹ç­‰æ­Œæ‰‹ä¸‹ Mic" : "";

  return (
    <div style={{ padding: 12 }}>
      <button
        onClick={singing ? stopSing : grabMic}
        disabled={grabDisabled}
        title={grabTitle}
        style={{
          opacity: grabDisabled ? 0.5 : 1,
          cursor: grabDisabled ? "not-allowed" : "pointer",
          marginRight: 8
        }}
      >
        {singing ? "ğŸ›‘ ä¸‹éº¥" : "ğŸ¤ ä¸Šéº¥"}
      </button>

      {/* <button
        onClick={shareTabAudio}
        disabled={!singing || sharing}
        title={!singing ? "è«‹å…ˆä¸Šéº¥" : sharing ? "å·²åˆ†äº«åˆ†é éŸ³" : ""}
        style={{
          opacity: !singing || sharing ? 0.5 : 1,
          cursor: !singing || sharing ? "not-allowed" : "pointer",
        }}
      >
        {sharing ? "âœ… å·²åˆ†äº«åˆ†é éŸ³" : "ğŸ“¢ åˆ†äº«åˆ†é éŸ³"}
      </button> */}
    </div>
  );
}
